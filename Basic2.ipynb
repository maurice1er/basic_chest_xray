{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piptorchvisionll albumentations==0.4.6\n",
    "from torch.nn import Module, AvgPool2d, MaxPool2d, BatchNorm2d, Conv2d, Linear as L, ReLU as R, Sigmoid as S, Sequential, NLLLoss as nll_loss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.functional import F\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path=\"chest_xray_20210414/\",sub_path='train', img_size=256,device='CPU', is_train=False):\n",
    "        self.path = path\n",
    "        self.img_size = img_size\n",
    "        self.sub_path = sub_path\n",
    "        self.device = device\n",
    "        self.is_train = is_train\n",
    "        #-------------------------------------------------------------#\n",
    "        self.samples = self.sampler()\n",
    "        self.transforms = self.transformer()\n",
    "        \n",
    "    def sampler(self):\n",
    "        \"\"\"CHARGEMENT DYNAMIQUE DE TOUTES LES IMAGES: NORMALE | PNEUMONIA\"\"\"\n",
    "        new_path = os.path.join(self.path, self.sub_path)\n",
    "        return [ (os.path.join(new_path,etat,i), etat) for etat in os.listdir(new_path) for i in os.listdir(new_path+\"/\"+etat)]\n",
    "        return [(self.transforms(i),j) for i,j in images]\n",
    "    \n",
    "    def transformer(self):\n",
    "        \"\"\"TRANSFORMATION DE NOTRE IMAGE AFIN DE REDUIRE LE BIAIS\"\"\"\n",
    "        if self.is_train:\n",
    "            transform = A.Compose([\n",
    "                A.CLAHE(),\n",
    "                A.RandomRotate90(),\n",
    "                A.DualTransform(), # adding\n",
    "                A.Transpose(),\n",
    "                A.Resize(height=self.img_size, width=self.img_size, interpolation=cv2.INTER_AREA), # RESIZE\n",
    "                A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "                A.Blur(blur_limit=3),\n",
    "                A.OpticalDistortion(),\n",
    "                A.GridDistortion(),\n",
    "                A.HueSaturationValue(),\n",
    "            ])\n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "                A.Resize(height=self.img_size, width=self.img_size, interpolation=cv2.INTER_AREA), # RESIZE\n",
    "            ])\n",
    "            \n",
    "        return transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sampler())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # GET ONE IMAGE\n",
    "        #try:\n",
    "        path_to_img, class_type =  self.samples[index]\n",
    "        #except Exception as ie:\n",
    "        #    print(\"Index n'existe pas; Taille maximale = {}\".format(self.__len__()))\n",
    "        #    path_to_img, class_type =  self.samples[-1]\n",
    "            \n",
    "        \n",
    "        # TANSFORM LABEL\n",
    "        class_type = 0 if class_type == \"NORMAL\" else 1\n",
    "        \n",
    "        # LOAD IMAGE\n",
    "        img = cv2.imread(path_to_img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # RESIZE IMAGE\n",
    "        img_resize = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        #print(img_resize.shape)\n",
    "        \n",
    "        \n",
    "        # AUGMENT IMAGE\n",
    "        import random\n",
    "        random.seed(42) \n",
    "        augmented_image = self.transforms(image=img_resize)['image']\n",
    "        ## CONVERT ARRAY NUMPY TO TENSOR\n",
    "        img_tensor = torch.from_numpy(augmented_image).float()\n",
    "        img_tensor = img_tensor.permute(2,0,1)        \n",
    "        \n",
    "        #print(img_tensor.size(),label_tensor.size())\n",
    "        # print(img_tensor.size())\n",
    "        #print(type(img_tensor))\n",
    "        \n",
    "        # SHOW IMAGE\n",
    "        #print(path_to_img,' ---- ',class_type)\n",
    "        # plt.axis('off')\n",
    "        # plt.title(\"PERSONNE {}\".format(str(self.samples[index][1])))\n",
    "        # plt.imshow(img_tensor)\n",
    "        \n",
    "        \n",
    "        return img_tensor, class_type\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(sub_path='train')\n",
    "test_dataset = PneumoniaDataset(sub_path='test', is_train=True)\n",
    "val_dataset = PneumoniaDataset(sub_path='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload(data, bSize=3, sFle=True, nWkr=1):\n",
    "    dataloader = DataLoader(\n",
    "                    data,\n",
    "                    batch_size=bSize,\n",
    "                    shuffle=sFle,\n",
    "                    num_workers=nWkr\n",
    "                )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataload = dataload(train_dataset)\n",
    "test_dataload = dataload(test_dataset, sFle=True)\n",
    "val_dataload = dataload(val_dataset, bSize=2, sFle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Output size after convolution filter\n",
    "#((w-f+2P)/s) +1\n",
    "\n",
    "#Input shape= (256,3,150,150)\n",
    "\n",
    "self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "#Shape= (256,12,150,150)\n",
    "self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "#Shape= (256,12,150,150)\n",
    "self.relu1=nn.ReLU()\n",
    "#Shape= (256,12,150,150)\n",
    "\n",
    "self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "#Reduce the image size be factor 2\n",
    "#Shape= (256,12,75,75)\n",
    "\n",
    "\n",
    "self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "#Shape= (256,20,75,75)\n",
    "self.relu2=nn.ReLU()\n",
    "#Shape= (256,20,75,75)\n",
    "\n",
    "\n",
    "\n",
    "self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "#Shape= (256,32,75,75)\n",
    "self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "#Shape= (256,32,75,75)\n",
    "self.relu3=nn.ReLU()\n",
    "Shape= (256,32,75,75)\n",
    "\n",
    "        \n",
    "#self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaFakeModel(Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaFakeModel, self).__init__()\n",
    "        \n",
    "        # Image size [3, 3, 256, 256]\n",
    "\n",
    "        \n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \"\"\"  # Shape = (3,12,256,256)\n",
    "\n",
    "        self.bn1 = BatchNorm2d(num_features=12)\n",
    "        # Shape= (3,12,256,256)\n",
    "\n",
    "        self.relu1 = R()\n",
    "        # Shape= (3,12,256,256)\n",
    "\n",
    "        self.pool1 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "        # Shape= (3,12,128,128)\n",
    "\n",
    "        \n",
    "        self.conv2 = Conv2d(in_channels=12, out_channels=6, kernel_size=2, stride=1, padding=1)\n",
    "        # Shape= (3,6,128,128)\n",
    "\n",
    "        self.relu2= R()\n",
    "        # Shape= (3,6,128,128)\n",
    "        \n",
    "        self.pool2 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "        # Shape= (3,12,64,64)\n",
    "\n",
    "\n",
    "        self.conv3 = Conv2d(in_channels=6, out_channels=2, kernel_size=2, stride=1, padding=1)\n",
    "        # Shape= (3,2,64,64)\n",
    "\n",
    "        self.bn3 = BatchNorm2d(num_features=2)\n",
    "        # Shape= (256,2,64,64)\n",
    "\n",
    "        self.relu3= R()\n",
    "        # Shape= (256,2,64,64)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        #self.fc = L(in_features=64 * 64 * 2,out_features=2)\n",
    "\n",
    "        # self.fc1 = L(in_features=200,out_features=100)\n",
    "        self.fc2 = L(256, 50)\n",
    "        self.fc3 = L(50, 2)\n",
    "        self.pool1 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "        self.relu2 = R()\n",
    "        self.sig = S()\n",
    "        self.bn1 = BatchNorm2d(num_features=12)\n",
    "        self.pool2 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \"\"\"x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        output = x.view(-1,64*64*2)\n",
    "        output = self.fc(output)\n",
    "        print(x.size())\"\"\"\n",
    "        \n",
    "        \n",
    "        # x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.sig(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        \n",
    "        bSz, _, _, _ = x.shape\n",
    "        x = x.view(bSz, -1)\n",
    "        \n",
    "        # print(x.size())\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        # bSz, _, _, _ = x.shape\n",
    "        # y_pred = x.view(bSz, -1)\n",
    "\n",
    "        # x = self.fc(y_pred)\n",
    "        \n",
    "        return x # F.log_softmax(y_pred, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class PneumoniaModel(Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(3, 8, 1)\n",
    "        self.pool = AvgPool2d(1)\n",
    "        self.linear = L(8,6)\n",
    "        \n",
    "        self.conv2 = Conv2d(6, 2, 1)\n",
    "        self.maxpool = MaxPool2d(2)\n",
    "        self.sigm = S(2)\n",
    "        \n",
    "        self.relu = R()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # x = \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        y = self.relu(x)\n",
    "        x = self.pool(y)\n",
    "        \n",
    "        bSz, _, _, _ = x.shape\n",
    "        y_pred = x.view(bSz, -1)\n",
    "        \n",
    "        return F.log_softmax(y_pred, dim=1) # y_pred #F.log_softmax(y_pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "myDevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(myDevice))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = PneumoniaModel()\n",
    "model.to(myDevice)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = torch.randn([1, 3, 256,256])\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m = model(X) #.train()\n",
    "m.to(myDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3328, -7.3406, -7.3769,  ..., -7.2592, -7.3410, -7.3651],\n",
       "        [-7.2998, -7.3777, -7.3192,  ..., -7.2863, -7.3309, -7.3137]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = PneumoniaFakeModel()\n",
    "mm.to(myDevice)\n",
    "\n",
    "# [N, C, W, H]\n",
    "X = torch.randn([2, 3, 256,256])\n",
    "\n",
    "\n",
    "m = mm(X)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, RMSprop\n",
    "from torch.nn import KLDivLoss, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def myAccuracy(y_pred, y_true):\n",
    "    \n",
    "    y_pred_softmax = F.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_ = torch.max(y_pred_softmax, dim=1)\n",
    "    \n",
    "    correct = (y_pred_ == y_true).float()\n",
    "    result = correct.sum() #/ len(correct)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PneumoniaFakeModel(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc2): Linear(in_features=256, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (sig): Sigmoid()\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellls = PneumoniaFakeModel()\n",
    "modellls.to(myDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerd/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(modellls.parameters(),lr=0.001, weight_decay=0.0001)\n",
    "loss_function = CrossEntropyLoss(size_average=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITER: 0 | EPOCH: 0  | LOSS = 1.6311827898025513  | ACC = 0.18269230769230768\n",
      "ITER: 0 | EPOCH: 1  | LOSS = 0.9519787430763245  | ACC = 0.2644230769230769\n",
      "ITER: 0 | EPOCH: 2  | LOSS = 0.7122829556465149  | ACC = 0.35096153846153844\n",
      "ITER: 0 | EPOCH: 3  | LOSS = 0.5724525451660156  | ACC = 0.40064102564102566\n",
      "ITER: 0 | EPOCH: 4  | LOSS = 0.5195545554161072  | ACC = 0.40224358974358976\n",
      "ITER: 0 | EPOCH: 5  | LOSS = 0.47556474804878235  | ACC = 0.40544871794871795\n",
      "ITER: 0 | EPOCH: 6  | LOSS = 0.4468417465686798  | ACC = 0.41185897435897434\n",
      "ITER: 1 | EPOCH: 0  | LOSS = 0.4253743886947632  | ACC = 0.4375\n",
      "ITER: 1 | EPOCH: 1  | LOSS = 0.4118540287017822  | ACC = 0.4310897435897436\n",
      "ITER: 1 | EPOCH: 2  | LOSS = 0.4015834331512451  | ACC = 0.45032051282051283\n",
      "ITER: 1 | EPOCH: 3  | LOSS = 0.38234731554985046  | ACC = 0.4599358974358974\n",
      "ITER: 1 | EPOCH: 4  | LOSS = 0.3778650164604187  | ACC = 0.48717948717948717\n",
      "ITER: 1 | EPOCH: 5  | LOSS = 0.3510117530822754  | ACC = 0.5\n",
      "ITER: 1 | EPOCH: 6  | LOSS = 0.35229796171188354  | ACC = 0.5016025641025641\n",
      "ITER: 2 | EPOCH: 0  | LOSS = 0.3464833199977875  | ACC = 0.5240384615384616\n",
      "ITER: 2 | EPOCH: 1  | LOSS = 0.33226194977760315  | ACC = 0.5192307692307693\n",
      "ITER: 2 | EPOCH: 2  | LOSS = 0.3239302635192871  | ACC = 0.5400641025641025\n",
      "ITER: 2 | EPOCH: 3  | LOSS = 0.32925617694854736  | ACC = 0.5512820512820513\n",
      "ITER: 2 | EPOCH: 4  | LOSS = 0.30349668860435486  | ACC = 0.5673076923076923\n",
      "ITER: 2 | EPOCH: 5  | LOSS = 0.29895564913749695  | ACC = 0.5833333333333334\n",
      "ITER: 2 | EPOCH: 6  | LOSS = 0.2857542037963867  | ACC = 0.6073717948717948\n",
      "ITER: 3 | EPOCH: 0  | LOSS = 0.2875281572341919  | ACC = 0.6201923076923077\n",
      "ITER: 3 | EPOCH: 1  | LOSS = 0.270153284072876  | ACC = 0.6346153846153846\n",
      "ITER: 3 | EPOCH: 2  | LOSS = 0.27951928973197937  | ACC = 0.6233974358974359\n",
      "ITER: 3 | EPOCH: 3  | LOSS = 0.2556932866573334  | ACC = 0.6794871794871795\n",
      "ITER: 3 | EPOCH: 4  | LOSS = 0.24488399922847748  | ACC = 0.6955128205128205\n",
      "ITER: 3 | EPOCH: 5  | LOSS = 0.23761947453022003  | ACC = 0.7003205128205128\n",
      "ITER: 3 | EPOCH: 6  | LOSS = 0.24966560304164886  | ACC = 0.6987179487179487\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "\n",
    "import torch\n",
    "for i in range(4):\n",
    "    for epoch in range(epochs):\n",
    "        modellls.train()\n",
    "        train_accuracy=0.0\n",
    "        train_loss=0.0\n",
    "        \n",
    "        for j, (inputs, labels) in enumerate(test_dataload):\n",
    "            images = inputs.to(myDevice)\n",
    "            labels = labels.to(myDevice)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs=modellls(images)\n",
    "            loss=loss_function(outputs,labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss\n",
    "            _, prediction = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "            \n",
    "        train_accuracy=train_accuracy/624\n",
    "        train_loss=train_loss/624\n",
    "        \n",
    "        print(\"ITER: {} | EPOCH: {}  | LOSS = {}  | ACC = {}\".format(i, epoch, train_loss, train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train():\n",
    "    epochs = 2\n",
    "\n",
    "    _accuracy = 0.0\n",
    "    _loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(val_dataload):\n",
    "\n",
    "            inputs = inputs.to(myDevice)\n",
    "            labels = labels.to(myDevice)\n",
    "\n",
    "            optimiz.zero_grad()\n",
    "            y_pred = model(inputs)\n",
    "            \n",
    "            acc = myAccuracy(y_pred, labels)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimiz.step()\n",
    "            \n",
    "            _accuracy += acc\n",
    "            _loss += loss.item()\n",
    "            \n",
    "            \n",
    "        _accuracy  = acc\n",
    "        _loss = loss\n",
    "            \n",
    "        print(\"C_LOSS = {}        |        C_ACC = {}\".format(_loss, _accuracy))\n",
    "        \n",
    "        # taille du val\n",
    "        #print(c_acc, c_acc/624)\n",
    "\n",
    "        #print(\"EPOCH {}   |   LOSS  {}\".format(epoch, c_loss))\n",
    "    \n",
    "        #c_acc = c_loss/624\n",
    "        #print(\"LOSS = {}   | ACCURACY = {}\".format(c_loss, str(c_acc)))\n",
    "    # return \"ACCURACY = {}\".format(str(c_acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(2):\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path=\"/\",sub_path='content/sample_data', img_size=256):\n",
    "        self.path = path\n",
    "        self.img_size = img_size\n",
    "        self.sub_path = sub_path\n",
    "        #-------------------------------------------------------------#\n",
    "        self.samples = self.sampler()\n",
    "        self.transforms = self.transformer()\n",
    "        \n",
    "    def sampler(self):\n",
    "        \"\"\"CHARGEMENT DYNAMIQUE DE TOUTES LES IMAGES: NORMALE | PNEUMONIA\"\"\"\n",
    "        new_path = os.path.join(self.path, self.sub_path)\n",
    "        return [ (os.path.join(new_path,etat,i), etat) for etat in os.listdir(new_path) for i in os.listdir(new_path+\"/\"+etat)]\n",
    "    \n",
    "    def transformer(self):\n",
    "        \"\"\"TRANSFORMATION DE NOTRE IMAGE AFIN DE REDUIRE LE BIAIS\"\"\"\n",
    "        transform = A.Compose([\n",
    "            A.CLAHE(),\n",
    "            A.RandomRotate90(),\n",
    "            A.DualTransform(), # adding\n",
    "            A.Transpose(),\n",
    "            A.Resize(height=256, width=256, interpolation=CV2.INTER_AREA), # RESIZE\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "            A.Blur(blur_limit=3),\n",
    "            A.OpticalDistortion(),\n",
    "            A.GridDistortion(),\n",
    "            A.HueSaturationValue(),\n",
    "        ])\n",
    "        return transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sampler())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # GET ONE IMAGE\n",
    "        try:\n",
    "            path_to_img, class_type =  self.samples[index]\n",
    "        except Exception as ie:\n",
    "            print(\"Index n'existe pas; Taille maximale = {}\".format(self.__len__()))\n",
    "            path_to_img, class_type =  self.samples[-1]\n",
    "            \n",
    "        \n",
    "        # TANSFORM LABEL\n",
    "        class_type = 0 if class_type == \"NORMAL\" else 1\n",
    "        \n",
    "        # LOAD IMAGE\n",
    "        img = cv2.imread(path_to_img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # RESIZE IMAGE\n",
    "        #img_resize = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        #print(img_resize.shape)\n",
    "        \n",
    "        # AUGMENT IMAGE\n",
    "        import random\n",
    "        random.seed(42) \n",
    "        augmented_image = self.transforms(image=img)['image']\n",
    "        \n",
    "        ## CONVERT ARRAY NUMPY TO TENSOR\n",
    "        # img_tensor = torch.from_numpy(augmented_image)\n",
    "        # label_tensor = torch.LongTensor(class_type).float()\n",
    "        \n",
    "        # print(label_tensor.size())\n",
    "        # print(type(img_tensor))\n",
    "        \n",
    "        # SHOW IMAGE\n",
    "        # print(path_to_img,' ---- ',class_type)\n",
    "        # plt.axis('off')\n",
    "        # plt.title(\"PERSONNE {}\".format(str(self.samples[index][1])))\n",
    "        # plt.imshow(img_tensor)\n",
    "\n",
    "        print(class_type.size())\n",
    "        \n",
    "        return img, class_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
