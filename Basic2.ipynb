{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piptorchvisionll albumentations==0.4.6\n",
    "from torch.nn import Module, AvgPool2d, MaxPool2d, BatchNorm2d, Conv2d, Linear as L, ReLU as R, Sigmoid as S, Sequential, NLLLoss as nll_loss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.functional import F\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path=\"chest_xray_20210414/\",sub_path='train', img_size=256,device='CPU', is_train=False):\n",
    "        self.path = path\n",
    "        self.img_size = img_size\n",
    "        self.sub_path = sub_path\n",
    "        self.device = device\n",
    "        self.is_train = is_train\n",
    "        #-------------------------------------------------------------#\n",
    "        self.samples = self.sampler()\n",
    "        self.transforms = self.transformer()\n",
    "        \n",
    "    def sampler(self):\n",
    "        \"\"\"CHARGEMENT DYNAMIQUE DE TOUTES LES IMAGES: NORMALE | PNEUMONIA\"\"\"\n",
    "        new_path = os.path.join(self.path, self.sub_path)\n",
    "        return [ (os.path.join(new_path,etat,i), etat) for etat in os.listdir(new_path) for i in os.listdir(new_path+\"/\"+etat)]\n",
    "        return [(self.transforms(i),j) for i,j in images]\n",
    "    \n",
    "    def transformer(self):\n",
    "        \"\"\"TRANSFORMATION DE NOTRE IMAGE AFIN DE REDUIRE LE BIAIS\"\"\"\n",
    "        if self.is_train:\n",
    "            transform = A.Compose([\n",
    "                A.CLAHE(),\n",
    "                A.RandomRotate90(),\n",
    "                A.DualTransform(), # adding\n",
    "                A.Transpose(),\n",
    "                A.Resize(height=self.img_size, width=self.img_size, interpolation=cv2.INTER_AREA), # RESIZE\n",
    "                A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "                A.Blur(blur_limit=3),\n",
    "                A.OpticalDistortion(),\n",
    "                A.GridDistortion(),\n",
    "                A.HueSaturationValue(),\n",
    "            ])\n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "                A.Resize(height=self.img_size, width=self.img_size, interpolation=cv2.INTER_AREA), # RESIZE\n",
    "            ])\n",
    "            \n",
    "        return transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sampler())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # GET ONE IMAGE\n",
    "        try:\n",
    "            path_to_img, class_type =  self.samples[index]\n",
    "        except Exception as ie:\n",
    "            print(\"Index n'existe pas; Taille maximale = {}\".format(self.__len__()))\n",
    "            path_to_img, class_type =  self.samples[-1]\n",
    "            \n",
    "        \n",
    "        # TANSFORM LABEL\n",
    "        class_type = 0 if class_type == \"NORMAL\" else 1\n",
    "        \n",
    "        # LOAD IMAGE\n",
    "        img = cv2.imread(path_to_img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # RESIZE IMAGE\n",
    "        img_resize = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)        \n",
    "        \n",
    "        # AUGMENT IMAGE\n",
    "        import random\n",
    "        random.seed(42) \n",
    "        augmented_image = self.transforms(image=img_resize)['image']\n",
    "        ## CONVERT ARRAY NUMPY TO TENSOR\n",
    "        img_tensor = torch.from_numpy(augmented_image).float()\n",
    "        img_tensor = img_tensor.permute(2,0,1)                \n",
    "        \n",
    "        return img_tensor, class_type\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(sub_path='train')\n",
    "test_dataset = PneumoniaDataset(sub_path='test', is_train=True)\n",
    "val_dataset = PneumoniaDataset(sub_path='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload(data, bSize=3, sFle=True, nWkr=1):\n",
    "    dataloader = DataLoader(\n",
    "                    data,\n",
    "                    batch_size=bSize,\n",
    "                    shuffle=sFle,\n",
    "                    num_workers=nWkr\n",
    "                )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataload = dataload(train_dataset)\n",
    "test_dataload = dataload(test_dataset, sFle=True)\n",
    "val_dataload = dataload(val_dataset, bSize=2, sFle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaFakeModel(Module):\n",
    "    def __init__(self):\n",
    "        super(PneumoniaFakeModel, self).__init__()\n",
    "        \n",
    "        # Image size [3, 3, 256, 256]\n",
    "\n",
    "        \n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc2 = L(256, 50)\n",
    "        self.fc3 = L(50, 2)\n",
    "        \n",
    "        self.pool1 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "        self.relu2 = R()\n",
    "        self.sig = S()\n",
    "        self.bn1 = BatchNorm2d(num_features=12)\n",
    "        self.pool2 = MaxPool2d(kernel_size=2) # Reduce the image size be factor 2\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.sig(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        bSz, _, _, _ = x.shape\n",
    "        x = x.view(bSz, -1)\n",
    "        \n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix du device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(myDevice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFk = PneumoniaFakeModel()\n",
    "modelFk.to(myDevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pseudo test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [N, C, W, H]\n",
    "X = torch.randn([2, 3, 256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = modelFk(X)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, RMSprop\n",
    "from torch.nn import KLDivLoss, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFake = PneumoniaFakeModel()\n",
    "modelFake.to(myDevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimizer et Fonction d'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(modelFake.parameters(),lr=0.001, weight_decay=0.0001)\n",
    "loss_function = CrossEntropyLoss(size_average=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entrainement du modele\n",
    "def entrainement(iteration, epochs, dataloader, model):\n",
    "    for i in range(iteration):\n",
    "        for epoch in range(epochs):\n",
    "            model.train() # on lance le modele en mode entrainement\n",
    "\n",
    "            train_accuracy=0.0 # initialisation\n",
    "            train_loss=0.0 # initialisation\n",
    "\n",
    "            for j, (inputs, labels) in enumerate(dataloader):\n",
    "                images = inputs.to(myDevice)\n",
    "                labels = labels.to(myDevice)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = loss_function(outputs,labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss\n",
    "                _, prediction = torch.max(outputs.data, dim=1)\n",
    "\n",
    "                train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            train_accuracy=train_accuracy/624\n",
    "            train_loss=train_loss/624\n",
    "\n",
    "            print(\"ITER: {} | EPOCH: {}  | LOSS = {}  | ACC = {}\".format(i, epoch, train_loss, train_accuracy))\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Pour l'entrainement du modele, je prendrai le dataloader du Test pour des raisons de ressources(memoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "entrainement(iteration=4, epochs=epochs, dataloader=test_dataload, model=modelFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
